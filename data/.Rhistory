Npred<-now$Npred
mh1=sum(dnorm(Nlat[-1,],(Npred.star[-1,]),sig.p,log=TRUE)) #implied uniform prior
mh2=sum(dnorm(Nlat[-1,],(Npred[-1,]),sig.p,log=TRUE))      #implied uniform prior
mh=min(exp(mh1-mh2),1)
if(mh>runif(1)){
M=M.star
Minv<-chol2inv(M.star)
tau<-tau.star
accept.tau=accept.tau+1
}
tauOut[i,]<-tau
for (t in 2:tmax){
Npred[t,]<-M%*%(diag(G[t,])%*%Nlat[t-1,])
}
sig.p<-sqrt(sampleSigma(Nlat=c(Nlat[-1,]),Npred=c(Npred[-1,]),a=3,b=.5))
sig.pOut[i,]<-sig.p
#sig.o<-sqrt(sampleObS(Nlat=c(Nlat),N=c(N),a=3,b=.5))
sig.oOut[i,]<-sig.o
for (t in 1:tmax){
Nlat[t,]<-sampleLatent(Npred,Nlat,N,G,M,Minv,sig.o,sig.p,tmax)
}
NlatOut[,,i]<-Nlat[,1:100]
print(i)
}
plot(sig.pOut[1:4,1],type='l')
plot(sig.pOut[1:45,1],type='l')
plot(sig.pOut[40:89,1],type='l')
###Starting Values###
Nlat<-N #Starting values for latent states is the observed data
beta<-c(.01,-.01) ###Give beta some starting values based on what we know
tau<-.1###Give tau a reasonable starting value.
sig.p<-.1##give sig.p reasonable starting values
o1<-sig.o<-1##give sig.o reasonable starting values
ro <- 0.5
qo1 <- (ro/o1)+1
Mint<-exp(-(D/tau))
M<-t(Mint/apply(Mint,1,sum))  ##calculate M starting M given Tau
Npred<-G<-matrix(NA,tmax,pmax)
for (t in 2:tmax){
G[t,]<-exp(beta[1]+beta[2]*Nlat[t-1,])
Npred[t,]<-M%*%(diag(G[t,])%*%Nlat[t-1,])
}
Niter<-20000 ###Number of interations. Keep in mind this will need to be more than you needed for stan
###Containers####
tauOut<-matrix(NA,Niter,)
betaOut<-matrix(NA,Niter,bmax)
NlatOut<-array(NA,c(36,100,Niter))
sig.pOut<-sig.oOut<-matrix(NA,Niter,1)
accept.beta=accept.tau=0
beta.tune=diag(c(.000001,.000001))
tau.tune=.001
for (i in 1:Niter){
beta.star=rmvnorm(1,beta,beta.tune)
Out=UpdateBeta(tmax=tmax,b=beta.star,Nlat=Nlat,M=M,p=p)
Npred.star<-Out$Npred
G.star<-Out$G
now=UpdateBeta(tmax=tmax,b=beta,Nlat=Nlat,M=M,p=p)
Npred<-now$Npred
mh1=sum(dnorm(Nlat[-1,],(Npred.star[-1,]),sig.p,log=TRUE)) #implied uniform prior
mh2=sum(dnorm(Nlat[-1,],(Npred[-1,]),sig.p,log=TRUE))      #implied uniform prior
mh=min(exp(mh1-mh2),1)
if(mh>runif(1)){
G=G.star
beta=beta.star
accept.beta=accept.beta+1
}
betaOut[i,]<-beta
tau.star=rnorm(1,tau,tau.tune)
Out=UpdateDispersal(tmax=tmax,tau=tau.star,Nlat=Nlat,G=G,p=p,D=D)
Npred.star<-Out$Npred
M.star<-Out$M
now=UpdateDispersal(tmax=tmax,tau=tau,Nlat=Nlat,G=G,p=p,D=D)
Npred<-now$Npred
mh1=sum(dnorm(Nlat[-1,],(Npred.star[-1,]),sig.p,log=TRUE)) #implied uniform prior
mh2=sum(dnorm(Nlat[-1,],(Npred[-1,]),sig.p,log=TRUE))      #implied uniform prior
mh=min(exp(mh1-mh2),1)
if(mh>runif(1)){
M=M.star
Minv<-chol2inv(M.star)
tau<-tau.star
accept.tau=accept.tau+1
}
tauOut[i,]<-tau
for (t in 2:tmax){
Npred[t,]<-M%*%(diag(G[t,])%*%Nlat[t-1,])
}
sig.p<-sqrt(sampleSigma(Nlat=c(Nlat[-1,]),Npred=c(Npred[-1,]),a=3,b=.5))
sig.pOut[i,]<-sig.p
#sig.o<-sqrt(sampleObS(Nlat=c(Nlat),N=c(N),a=3,b=.5))
sig.oOut[i,]<-sig.o
for (t in 1:tmax){
Nlat[t,]<-sampleLatent(Npred,Nlat,N,G,M,Minv,sig.o,sig.p,tmax)
}
NlatOut[,,i]<-Nlat[,1:100]
print(i)
}
plot(sig.pOut[40:5000,1],type='l')
plot(betaOut[40:5000,1],type='l')
plot(betaOut[40:5000,2],type='l')
plot(NlatOut[40:5000,3],type='l')
plot(NlatOut[1,1,140:5000],type='l')
###Starting Values###
Nlat<-N #Starting values for latent states is the observed data
beta<-c(.01,-.01) ###Give beta some starting values based on what we know
tau<-.1###Give tau a reasonable starting value.
sig.p<-.1##give sig.p reasonable starting values
o1<-sig.o<-1##give sig.o reasonable starting values
ro <- 0.5
qo1 <- (ro/o1)+1
Mint<-exp(-(D/tau))
M<-t(Mint/apply(Mint,1,sum))  ##calculate M starting M given Tau
Npred<-G<-matrix(NA,tmax,pmax)
for (t in 2:tmax){
G[t,]<-exp(beta[1]+beta[2]*Nlat[t-1,])
Npred[t,]<-M%*%(diag(G[t,])%*%Nlat[t-1,])
}
Niter<-20000 ###Number of interations. Keep in mind this will need to be more than you needed for stan
checkpoint=Niter*0.01
###Containers####
tauOut<-matrix(NA,Niter,)
betaOut<-matrix(NA,Niter,bmax)
NlatOut<-array(NA,c(36,100,Niter))
sig.pOut<-sig.oOut<-matrix(NA,Niter,1)
accept.beta=accept.tau=0
beta.tune=diag(c(.000001,.000001))
tau.tune=.001
for (i in 1:Niter){
beta.star=rmvnorm(1,beta,beta.tune)
Out=UpdateBeta(tmax=tmax,b=beta.star,Nlat=Nlat,M=M,p=p)
Npred.star<-Out$Npred
G.star<-Out$G
now=UpdateBeta(tmax=tmax,b=beta,Nlat=Nlat,M=M,p=p)
Npred<-now$Npred
mh1=sum(dnorm(Nlat[-1,],(Npred.star[-1,]),sig.p,log=TRUE)) #implied uniform prior
mh2=sum(dnorm(Nlat[-1,],(Npred[-1,]),sig.p,log=TRUE))      #implied uniform prior
mh=min(exp(mh1-mh2),1)
if(mh>runif(1)){
G=G.star
beta=beta.star
accept.beta=accept.beta+1
}
betaOut[i,]<-beta
tau.star=rnorm(1,tau,tau.tune)
Out=UpdateDispersal(tmax=tmax,tau=tau.star,Nlat=Nlat,G=G,p=p,D=D)
Npred.star<-Out$Npred
M.star<-Out$M
now=UpdateDispersal(tmax=tmax,tau=tau,Nlat=Nlat,G=G,p=p,D=D)
Npred<-now$Npred
mh1=sum(dnorm(Nlat[-1,],(Npred.star[-1,]),sig.p,log=TRUE)) #implied uniform prior
mh2=sum(dnorm(Nlat[-1,],(Npred[-1,]),sig.p,log=TRUE))      #implied uniform prior
mh=min(exp(mh1-mh2),1)
if(mh>runif(1)){
M=M.star
Minv<-chol2inv(M.star)
tau<-tau.star
accept.tau=accept.tau+1
}
tauOut[i,]<-tau
for (t in 2:tmax){
Npred[t,]<-M%*%(diag(G[t,])%*%Nlat[t-1,])
}
sig.p<-sqrt(sampleSigma(Nlat=c(Nlat[-1,]),Npred=c(Npred[-1,]),a=3,b=.5))
sig.pOut[i,]<-sig.p
#sig.o<-sqrt(sampleObS(Nlat=c(Nlat),N=c(N),a=3,b=.5))
sig.oOut[i,]<-sig.o
for (t in 1:tmax){
Nlat[t,]<-sampleLatent(Npred,Nlat,N,G,M,Minv,sig.o,sig.p,tmax)
}
NlatOut[,,i]<-Nlat[,1:100]
print(i)
if(i%%checkpoint==0){
if(accept.beta/i<0.35) beta.tune=beta.tune*.9
if(accept.beta/i>0.45) beta.tune=beta.tune*1.1
if(accept.tau/i<0.35) tau.tune=tau.tune*.9
if(accept.tau/i>0.45) tau.tune=tau.tune*1.1
}
}
###Starting Values###
Nlat<-N #Starting values for latent states is the observed data
beta<-c(.01,-.01) ###Give beta some starting values based on what we know
tau<-.1###Give tau a reasonable starting value.
sig.p<-.1##give sig.p reasonable starting values
o1<-sig.o<-1##give sig.o reasonable starting values
ro <- 0.5
qo1 <- (ro/o1)+1
Mint<-exp(-(D/tau))
M<-t(Mint/apply(Mint,1,sum))  ##calculate M starting M given Tau
Npred<-G<-matrix(NA,tmax,pmax)
for (t in 2:tmax){
G[t,]<-exp(beta[1]+beta[2]*Nlat[t-1,])
Npred[t,]<-M%*%(diag(G[t,])%*%Nlat[t-1,])
}
Niter<-5000 ###Number of interations. Keep in mind this will need to be more than you needed for stan
checkpoint=Niter*0.01
###Containers####
tauOut<-matrix(NA,Niter,)
betaOut<-matrix(NA,Niter,bmax)
NlatOut<-array(NA,c(36,100,Niter))
sig.pOut<-sig.oOut<-matrix(NA,Niter,1)
accept.beta=accept.tau=0
beta.tune=diag(c(.000001,.000001))
tau.tune=.001
for (i in 1:Niter){
beta.star=rmvnorm(1,beta,beta.tune)
Out=UpdateBeta(tmax=tmax,b=beta.star,Nlat=Nlat,M=M,p=p)
Npred.star<-Out$Npred
G.star<-Out$G
now=UpdateBeta(tmax=tmax,b=beta,Nlat=Nlat,M=M,p=p)
Npred<-now$Npred
mh1=sum(dnorm(Nlat[-1,],(Npred.star[-1,]),sig.p,log=TRUE)) #implied uniform prior
mh2=sum(dnorm(Nlat[-1,],(Npred[-1,]),sig.p,log=TRUE))      #implied uniform prior
mh=min(exp(mh1-mh2),1)
if(mh>runif(1)){
G=G.star
beta=beta.star
accept.beta=accept.beta+1
}
betaOut[i,]<-beta
tau.star=rnorm(1,tau,tau.tune)
Out=UpdateDispersal(tmax=tmax,tau=tau.star,Nlat=Nlat,G=G,p=p,D=D)
Npred.star<-Out$Npred
M.star<-Out$M
now=UpdateDispersal(tmax=tmax,tau=tau,Nlat=Nlat,G=G,p=p,D=D)
Npred<-now$Npred
mh1=sum(dnorm(Nlat[-1,],(Npred.star[-1,]),sig.p,log=TRUE)) #implied uniform prior
mh2=sum(dnorm(Nlat[-1,],(Npred[-1,]),sig.p,log=TRUE))      #implied uniform prior
mh=min(exp(mh1-mh2),1)
if(mh>runif(1)){
M=M.star
Minv<-chol2inv(M.star)
tau<-tau.star
accept.tau=accept.tau+1
}
tauOut[i,]<-tau
for (t in 2:tmax){
Npred[t,]<-M%*%(diag(G[t,])%*%Nlat[t-1,])
}
sig.p<-sqrt(sampleSigma(Nlat=c(Nlat[-1,]),Npred=c(Npred[-1,]),a=3,b=.5))
sig.pOut[i,]<-sig.p
#sig.o<-sqrt(sampleObS(Nlat=c(Nlat),N=c(N),a=3,b=.5))
sig.oOut[i,]<-sig.o
for (t in 1:tmax){
Nlat[t,]<-sampleLatent(Npred,Nlat,N,G,M,Minv,sig.o,sig.p,tmax)
}
NlatOut[,,i]<-Nlat[,1:100]
print(i)
if(i%%checkpoint==0){
if(accept.beta/i<0.35) beta.tune=beta.tune*.9
if(accept.beta/i>0.45) beta.tune=beta.tune*1.1
if(accept.tau/i<0.35) tau.tune=tau.tune*.9
if(accept.tau/i>0.45) tau.tune=tau.tune*1.1
}
}
plot(sig.pOut[1:68,1],type='l')
plot(betaOut[1:68,1],type='l')
plot(betaOut[1:68,2],type='l')
for (i in 69:Niter){
beta.star=rmvnorm(1,beta,beta.tune)
Out=UpdateBeta(tmax=tmax,b=beta.star,Nlat=Nlat,M=M,p=p)
Npred.star<-Out$Npred
G.star<-Out$G
now=UpdateBeta(tmax=tmax,b=beta,Nlat=Nlat,M=M,p=p)
Npred<-now$Npred
mh1=sum(dnorm(Nlat[-1,],(Npred.star[-1,]),sig.p,log=TRUE)) #implied uniform prior
mh2=sum(dnorm(Nlat[-1,],(Npred[-1,]),sig.p,log=TRUE))      #implied uniform prior
mh=min(exp(mh1-mh2),1)
if(mh>runif(1)){
G=G.star
beta=beta.star
accept.beta=accept.beta+1
}
betaOut[i,]<-beta
tau.star=rnorm(1,tau,tau.tune)
Out=UpdateDispersal(tmax=tmax,tau=tau.star,Nlat=Nlat,G=G,p=p,D=D)
Npred.star<-Out$Npred
M.star<-Out$M
now=UpdateDispersal(tmax=tmax,tau=tau,Nlat=Nlat,G=G,p=p,D=D)
Npred<-now$Npred
mh1=sum(dnorm(Nlat[-1,],(Npred.star[-1,]),sig.p,log=TRUE)) #implied uniform prior
mh2=sum(dnorm(Nlat[-1,],(Npred[-1,]),sig.p,log=TRUE))      #implied uniform prior
mh=min(exp(mh1-mh2),1)
if(mh>runif(1)){
M=M.star
Minv<-chol2inv(M.star)
tau<-tau.star
accept.tau=accept.tau+1
}
tauOut[i,]<-tau
for (t in 2:tmax){
Npred[t,]<-M%*%(diag(G[t,])%*%Nlat[t-1,])
}
sig.p<-sqrt(sampleSigma(Nlat=c(Nlat[-1,]),Npred=c(Npred[-1,]),a=3,b=.5))
sig.pOut[i,]<-sig.p
#sig.o<-sqrt(sampleObS(Nlat=c(Nlat),N=c(N),a=3,b=.5))
sig.oOut[i,]<-sig.o
for (t in 1:tmax){
Nlat[t,]<-sampleLatent(Npred,Nlat,N,G,M,Minv,sig.o,sig.p,tmax)
}
NlatOut[,,i]<-Nlat[,1:100]
print(i)
if(i%%checkpoint==0){
if(accept.beta/i<0.35) beta.tune=beta.tune*.9
if(accept.beta/i>0.45) beta.tune=beta.tune*1.1
if(accept.tau/i<0.35) tau.tune=tau.tune*.9
if(accept.tau/i>0.45) tau.tune=tau.tune*1.1
}
}
plot(betaOut[1:205,2],type='l')
2000*36
500*36
100*36
28/50
4/5
3.5
3.5/5
36/50
3/5
34/50
85,000*.65
85000*.65
65000+7000
65000+8000
429484+7500
408467+12500
38/40
38/50
(38+4+5+4.5)/(65)
(38+4+5+4.5+4)/(65)
4+4.5+5+4.5+4.5+4
40+26.5
66.5/75
3.5+4+4+5+4.5
51/75
4+5+5+4.5+5
44+23.6
67.5/75
48+29
4.5+4+3+4.5+5+4
25+38
63/75
34+27.5
61.5/75
67.5
67.5/75
5+4+4.5+3+4
58.5/75
32+23.5
55.5/75
3.5+5+5+4+3+5
35.5+36
25.5+36
61.5/75
38+27.5
65.5/75
1.5+2.5+5+4+4.5+4
21.6+26
47.5/75
5+3+4.5+3+5
58.5/75
50/25
20/25
38/50
58.5/75
3.5+3+5+1+3.5
32+16
48/75
70/75
5+3.5+5+5+5=4.5
5+3.5+5+5+5+4.5
28+46
5+4+4.5+4+4
5+4+4.5+4+4+4
25.5+38
63.5/75
44+27.5
71.5/75
134/(21/24)
5511/461
461/5511
50000000/107639
1/.3
136/(21/24)
20.4*5
5/100
5/20
20*.05
2100*12
28000-2200
2800-2200
600/2
600/12
30800-2200
(30800-2200)/12
2200*12
2100*2
2100*12
100/2100
2200/2
2200/12
2400*12
13000*.07
2100*12
25200+3000
28200/12
2200/2
2200/12
183/9
2205*2
2205*12
2350-2100
2350-2100-185
65*12
65/2100
67*12
804/2400
804/24000
.9^(1?10)
.9^(1/10)
.8^(1/10)
# step 1:
data = read.csv('./../data/portal_timeseries.csv')
setwd("/Volumes/GoogleDrive-105877584494075865262/My Drive/UNR/Classes/EcoForcast/UNR-EcoForcast/data")
# step 1:
data = read.csv('portal_timeseries.csv')
n<-length(data$NDVI)
datafit<-data[1:(n-10),] ##This is our "observed data
dim(datafit)
nfit<-length(datafit$NDVI)
# want a regression for NDVI last month and NDVI this month
model<-glm(NDVI[-1]~NDVI[-(nfit)],data=datafit)
plot(x=datafit$NDVI[-1], y=datafit$NDVI[-(nfit)])
abline(model, col = "darkgreen")
model
# step 2: Create a function to forecast the NDVI
int <- as.numeric(model$coefficients[1])
k <- as.numeric(model$coefficients[2])
# Function forecast the NDVI
# intercept + slope * previous NDVI, start at last NDVI used for model fit
Future_NDVI = function(int,k,NDVI,t){
NDVI_out <-numeric(t)
NDVI_out[1] <-NDVI
for(i in 2:t){
NDVI_out[i] = int + k * NDVI[i-1]
}
return(NDVI_out)
}
# quick function check
tempout<-Future_NDVI(int=int,k=k, NDVI= data$NDVI, t=2)
hist(data$NDVI)
hist(tempout)
# Forecast:
Forecast1 <-Future_NDVI(int=int,k=k, NDVI=data$NDVI[(n-10):n],t=11)
# Plot test data  # points(data$NDVI[(n-10):n
#par(mfrow=c(2,1))
plot(1:11,Forecast1,ylab='NDVI',xlab='Month', type='l', ylim=c(0,.5))
points(data$NDVI[(n-10):n], col='red')
# Plot added covariate for rain:
model2<-glm(NDVI[-1]~NDVI[-(nfit)]+rain[-(nfit)],data=datafit)
model2
raint_1<-data$rain[(n-10):(n-1)]
beta<-c(model2$coefficients)
FutureNDVI_rain<-function(b0,b1,b2,NDVI,t){
NDVI_out<-numeric(t)
NDVI_out[1]<-NDVI
for (i in 2:t){
NDVI_out[i]<-b0+b1*NDVI_out[i-1]+b2*raint_1[i-1]
}
return(NDVI_out)
}
Forecast2<-FutureNDVI_rain(b0=beta[1],b1=beta[2],b2=beta[3],NDVI=datafit$NDVI[nfit],t=11)
plot(1:11,Forecast2,ylab='NDVI',xlab='Month', type='l',ylim=c(0,.5), col="skyblue4")
points(data$NDVI[(n-10):n], col='red')
lines(1:11,Forecast1,ylab='NDVI',xlab='Month', type='l', ylim=c(0,.5), col="darkgreen")
mtext(c("NDVI forcast", "NDVI Rain forecast", "Obs"), side=3, line=c(1,2,3), col=c("darkgreen", "skyblue4", "red"))
# Lab 4
# Calculate RMSE of both NDVI forecasts.
# Do this cumulative across month. E.g. Month 1, then Month 1 and 2, then
# 1, 2, and 3, etc. (Hint: do this in a for loop)
# What month do the forecasts diverge? why?
# par(mfrow=c(2,1))
plot(data$NDVI[(n-10):n], Forecast1,)
abline(model, col="goldenrod")
plot(data$NDVI[(n-10):n],Forecast2)
abline(model2, col="red")
## RMSE
RMSE_F1 = mean((data$NDVI[(n-10):n] - Forecast1)^2) %>% sqrt()
RMSE_F2 = mean((data$NDVI[(n-10):n] - Forecast2)^2) %>% sqrt()
# slightly lower RMSE for model 2
?RMSE()
# what about packages?
library(tidyverse)
library(caret)
?RMSE()
RMSE(Forecast1, data$NDVI[(n-10):n])
# same value, for RMSE, which is nice.
#RMSE by month
Monthly_RMSE = function(forecast,obs,t){
RMSE_out <-numeric(t)
for(i in 2:t){
RMSE_out[i] = RMSE(forecast[i-1],obs[i-1])
}
return(RMSE_out)
}
Monthly_RMSE_F1 <- Monthly_RMSE(Forecast1, data$NDVI[(n-10):n], t=11)
Monthly_RMSE_F2 <- Monthly_RMSE(Forecast2, data$NDVI[(n-10):n], t=11)
plot(Monthly_RMSE_F2)
plot(Monthly_RMSE_F1, col="darkgreen")
lines(Monthly_RMSE_F1, col="darkgreen")
points(Monthly_RMSE_F2, col="skyblue4")
lines(Monthly_RMSE_F2, col="skyblue4")
mtext(c("NDVI forcast (1)", "NDVI Rain forecast (2)"), side=3, line=c(1,2), col=c("darkgreen", "skyblue4"))
mean(Monthly_RMSE_F2)- mean(Monthly_RMSE_F1)
